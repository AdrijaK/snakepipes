#!/usr/bin/env python3

__description__ = """
MPI-IE workflow for preprocessing

usage example:
    preprocessing -i input-dir -o output-dir --optDedupDist 2500 --clumpifyOptions
"""


import argparse
import os
import sys
import textwrap
import snakePipes.common_functions as cf
import snakePipes.parserCommon as parserCommon


def parse_args(defaults={"verbose": False, "configFile": None,
                         "clusterConfigFile": None, "maxJobs": 5,
                         "snakemakeOptions": "--use-conda", "tempDir": None,
                         "fastqc": False, "optDedupDist": 2500,
                         "clumpifyOptions": "dupesubs=0 qin=33 markduplicates=t optical=t",
                         "clumpifyMemory": "30G", "sampleSheet": "",
                         "ext": ".fastq.gz", "reads": ["_R1", "_R2"],
                         "UMIDedup": False, "UMIDedupOpts": "",
                         "UMIDedupSep": "_", "UMIBarcode": False,
                         "bcPattern": ""}):
    """
    Parse arguments from the command line.
    """
    mainArgs = parserCommon.mainArguments(defaults, preprocessing=True)

    parser = argparse.ArgumentParser(
        prog=sys.argv[0],
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=textwrap.dedent(__description__),
        parents=[mainArgs],
        add_help=False
    )

    # Workflow options
    optional = parser.add_argument_group('Options')
    parserCommon.commonOptions(optional, defaults, preprocessing=True)

    optional.add_argument("--optDedupDist",
                          type=int,
                          help="The maximum distance between clusters to mark one as "
                          "an optical duplicate of the other. Setting this to 0 will "
                          "disable optical deduplication, which is only needed on "
                          "patterned flow cells (NextSeq, NovaSeq, HiSeq 3000/4000, "
                          "etc.). Common values are: 2500 (HiSeq 3000/4000), 40 "
                          "(NextSeq) or 12000 (NovaSeq). (default: '%(default)s')",
                          default=defaults["optDedupDist"])

    optional.add_argument("--clumpifyOptions",
                          help="Options passed to clumpify, which should generally "
                          "NOT be changed. The exception to this is with NextSeq runs, "
                          "where 'spany=t adjacent=t' should be ADDED.",
                          default=defaults["clumpifyOptions"])

    optional.add_argument("--clumpifyMemory",
                          help="This controls how much memory clumpify is instructed "
                          "to use per-core, in GB. This may need to be increased if "
                          "samples are particularly large or there are MANY optical "
                          "duplicates. This is passed to both clumpify (e.g., as "
                          "-Xmx30G) and the cluster (e.g., as 30G). "
                          "(default: '%(default)s')",
                          default=defaults["clumpifyMemory"])

    optional.add_argument("--sampleSheet",
                          help="Information on samples (required for merging across lanes); see "
                               "'docs/content/preprocessing_sampleSheet.example.tsv' for an example."
                               " The first set of columns should hold the current sample names"
                               " (excluding things like _R1.fastq.gz or _1.fastq.gz) while the"
                               " second holds the name that the final sample should have (again,"
                               " excluding things like _R1.fastq.gz or _1.fastq.gz)."
                               " (default: '%(default)s')",
                          default=defaults["sampleSheet"])

    return parser


def main():
    baseDir, workflowDir, defaults = cf.setDefaults(os.path.basename(__file__))

    # get command line arguments
    parser = parse_args(defaults)
    args = parser.parse_args()
    args, defaults = cf.handleUserArgs(args, defaults, parse_args)

    # we also add these paths to config, although we don't use them in the Snakefile
    args.baseDir = baseDir

    # Common arguments
    cf.checkCommonArguments(args, baseDir, outDir=True)

    # Handle YAML and log files

    snakemake_cmd = cf.commonYAMLandLogs(baseDir, workflowDir, defaults, args, __file__)
    logfile_name = cf.logAndExport(args, os.path.basename(__file__))

    # Run everything
    cf.runAndCleanup(args, snakemake_cmd, logfile_name)


if __name__ == "__main__":
    main()
