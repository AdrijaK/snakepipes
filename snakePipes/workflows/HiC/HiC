#!/usr/bin/env python3

__version__ = "0.7.1"

__description__ = """
Hi-C workflow v{version} - MPI-IE workflow for Hi-C analysis

usage example:
    HiC -i input-dir -o output-dir mm10
""".format(version=__version__)


import argparse
import os
import signal
import subprocess
import sys
import textwrap
import time
import shutil
import yaml
import inspect
from glob import glob
import snakePipes.common_functions as cf
import snakePipes.parserCommon as parserCommon


def parse_args(defaults={"verbose":None,"configfile":None,"cluster_configfile":None,"max_jobs":None,"snakemake_options":None,"tempdir":None,
                         "mode":None, "downsample":None, "trim":None,"trim_prg":None,"trim_options":None, "fastqc":None,
                         "bin_size":None, "RF_resolution":None, "enzyme":None, "restrict_region":None,
                         "merge_samples":None, "nbins_toMerge":None, "tadparams":None, "noTAD":None, "noCorrect":None, "distVsCount":None, "distVsCountParams":None}):
    """
    Parse arguments from the command line.
    """
    mainArgs = parserCommon.mainArguments(defaults)

    parser = argparse.ArgumentParser(
        prog=sys.argv[0],
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=textwrap.dedent(__description__),
        parents=[mainArgs],
        add_help=False
    )

    # Workflow options
    optional = parser.add_argument_group('optional')

    optional.add_argument("--downsample",
                          dest="downsample",
                          metavar="INT",
                          help="downsample the given number of reads randomly from of each FASTQ file (default: '%(default)s')",
                          type=int,
                          default=defaults["downsample"])

    optional.add_argument("--trim",
                          dest="trim",
                          action="store_true",
                          help="Activate fastq read trimming. If activated, Illumina adaptors are trimmed by default. "
                          "Additional parameters can be specified under --trim_options (default: '%(default)s')",
                          default=defaults["trim"])

    optional.add_argument("--trim_prg",
                          dest="trim_prg",
                          choices=['cutadapt', 'trimgalore'],
                          help="trimming program: Cutadapt or TrimGalore (default: '%(default)s')",
                          default=defaults["trim_prg"])

    optional.add_argument("--trim_options",
                          dest="trim_options",
                          metavar="STR",
                          type=str,
                          help="Additional option string for trimming program of choice. (default: '%(default)s')",
                          default=defaults["trim_options"])

    optional.add_argument("--fastqc",
                          dest="fastqc",
                          action="store_true",
                          help="run FastQC read quality control (default: '%(default)s')",
                          default=defaults["fastqc"])

    optional.add_argument("--RF_resolution",
                          dest="RF_resolution",
                          action="store_true",
                          help="Create Hi-C matrices at restriction fragment resolution. Using RF "
                          "resolution would override the --bin_size argument. (default: '%(default)s')",
                          default=defaults["RF_resolution"])

    optional.add_argument("--enzyme",
                          dest="enzyme",
                          choices=['DpnII', 'HindIII'],
                          help="Which enzyme was used to create Hi-C library (default: '%(default)s')",
                          default=defaults["enzyme"])

    optional.add_argument("--bin_size",
                          dest="bin_size",
                          type=int,
                          metavar="INT",
                          help="Create Hi-C matrices at a given bin_size (default: '%(default)s')",
                          default=defaults["bin_size"])

    optional.add_argument("--restrict_region",
                          dest="restrict_region",
                          type=str,
                          metavar="STR",
                          help="Restrict building of HiC Matrix to given region [Chr:Start-End]. "
                          "Only one chromosome can also be specified (default: '%(default)s')",
                          default=defaults["restrict_region"])

    optional.add_argument("--merge_samples",
                          dest="merge_samples",
                          action="store_true",
                          help="Merge all HiC matrices and create a new matrix. (default: '%(default)s')",
                          default=defaults["merge_samples"])

    optional.add_argument("--merge_bins",
                          dest="nbins_toMerge",
                          type=int,
                          help="If > 0 , create a lower resolution HiC matrix for each sample "
                          "by merging the given number of bins. (default: '%(default)s')",
                          default=defaults["nbins_toMerge"])

    optional.add_argument("--findTADs_params",
                          dest="tadparams",
                          type=str,
                          metavar="STR",
                          help="parameters for HiCFindTADs. (default: '%(default)s')",
                          default=defaults["tadparams"])

    optional.add_argument("--noTAD",
                          dest="noTAD",
                          action="store_true",
                          help="Stop the pipeline before TAD calling. (default: '%(default)s')",
                          default=defaults["noTAD"])

    optional.add_argument("--noCorrect",
                          dest="noCorrect",
                          action="store_true",
                          help="Stop the pipeline before correcting the matrix. (default: '%(default)s')",
                          default=defaults["noCorrect"])

    optional.add_argument("--distVsCount",
                          dest="distVsCount",
                          action="store_true",
                          help="Run hicDistVsCount. (default: '%(default)s')",
                          default=defaults["distVsCount"])

    optional.add_argument("--distVsCount_params",
                          dest="distVsCountParams",
                          type=str,
                          metavar="STR",
                          help="parameters to run hicDistVsCount. (default: '%(default)s')",
                          default=defaults["distVsCountParams"])

    return parser


def main():
    # Script-neutral paths
    baseDir = os.path.dirname(cf.__file__)
    workflowDir = os.path.join(baseDir, "workflows", os.path.basename(__file__))

    ## defaults
    defaults = cf.load_configfile(os.path.join(workflowDir, "defaults.yaml"),False)

    ## get command line arguments
    parser = parse_args(defaults)
    args = parser.parse_args()

    ## we also add these paths to config, although we don't use them in the Snakefile
    args.baseDir = baseDir

    args.outdir = os.path.abspath(args.outdir)
    args.cluster_logs_dir = os.path.join(args.outdir, "cluster_logs")

    ## checks for parameters necessary in wrapper
    # 1. Dir path
    if os.path.exists(args.indir):
        args.indir = os.path.abspath(args.indir)
    else:
        sys.exit("\nError! Input dir not found! ({})\n".format(args.indir))
    # 2. config file
    if args.configfile and not os.path.exists(args.configfile):
        sys.exit("\nError! Provided configfile (-c) not found! ({})\n".format(args.configfile))
    # 3. get abspath from user provided genome/organism file
    if not os.path.isfile(os.path.join(baseDir, "shared/organisms/{}.yaml".format(args.genome))) and os.path.isfile(args.genome):
        args.genome = os.path.abspath(args.genome)

    ## merge configuration dicts
    config = defaults   # 1) form defaults.yaml
    if args.configfile:
        user_config = cf.load_configfile(args.configfile, False)
        config = cf.merge_dicts(config, user_config) # 2) form user_config.yaml
    config_wrap = cf.config_diff(vars(args), defaults) # 3) from wrapper parameters
    config = cf.merge_dicts(config, config_wrap)

    ## Output directory + log directory
    subprocess.call("[ -d {cluster_logs_dir} ] || mkdir -p {cluster_logs_dir}".format(cluster_logs_dir=args.cluster_logs_dir), shell=True)

    ## save to configs.yaml in outdir
    cf.write_configfile(os.path.join(args.outdir, 'config.yaml'), config)

    ## merge cluster config files: 1) global one, 2) workflow specific one, 3) user provided one
    cluster_config = cf.load_configfile(os.path.join(baseDir, "shared/cluster.yaml"), False)
    cluster_config = cf.merge_dicts(cluster_config, cf.load_configfile(os.path.join(workflowDir, "cluster.yaml"), False), )

    if args.cluster_configfile:
        user_cluster_config = cf.load_configfile(args.cluster_configfile, False)
        cluster_config = cf.merge_dicts(cluster_config, user_cluster_config) # 2) merge/override variables from user_config.yaml
    cf.write_configfile(os.path.join(args.outdir, 'cluster_config.yaml'), cluster_config)

    snakemake_cmd = """
                    snakemake {snakemake_options} --latency-wait {latency_wait} --snakefile {snakefile} --jobs {max_jobs} --directory {outdir} --configfile {configfile}
                    """.format( latency_wait = cluster_config["snakemake_latency_wait"],
                                snakefile = os.path.join(workflowDir, "Snakefile"),
                                max_jobs = args.max_jobs,
                                outdir = args.outdir,
                                snakemake_options = str(args.snakemake_options or ''),
                                configfile = os.path.join(args.outdir, 'config.yaml'),
                              ).split()

    # Produce the DAG if desired
    if args.createDAG:
        oldVerbose = config['verbose']
        config['verbose'] = False
        cf.write_configfile(os.path.join(args.outdir,'config.yaml'), config)
        DAGproc = subprocess.Popen(snakemake_cmd + ['--rulegraph'], stdout=subprocess.PIPE)
        _ = open("{}/pipeline.pdf".format(args.outdir), "wb")
        foo = subprocess.check_call(["dot", "-Tpdf"], stdin=DAGproc.stdout, stdout=_)
        _.close()
        config['verbose'] = oldVerbose
        cf.write_configfile(os.path.join(args.outdir, 'config.yaml'), config)

    if args.verbose:
        snakemake_cmd.append("--printshellcmds ")

    if not args.local:
        snakemake_cmd += ["--cluster-config",
                          os.path.join(args.outdir, 'cluster_config.yaml'),
                          "--cluster", "'"+cluster_config["snakemake_cluster_cmd"],
                          args.cluster_logs_dir, "--name {rule}.snakemake'"]

    ## Write snakemake_cmd to log file
    fnames = glob(os.path.join(args.outdir, 'Hi-C_run-[0-9*].log'))
    if len(fnames) == 0:
        n = 1 # no matching files, this is the first run
    else:
        fnames.sort(key=os.path.getctime)
        n = int(fnames[-1].split("-")[-1].split(".")[0]) + 1 # get new run number
    # append the new run number to the file name
    logfile_name = "Hi-C_run-{}.log".format(n) 

    snakemake_log = "2>&1 | tee -a {}/{}".format(args.outdir, logfile_name).split()

    ## create local temp dir and add this path to environment as $TMPDIR variable
    ## on SLURM: $TMPDIR is set, created and removed by SlurmEasy on cluster node
    temp_path = cf.make_temp_dir(args.tempdir, args.outdir, args.verbose)
    snakemake_exports = ("export TMPDIR="+temp_path+" && ").split()

    cmd = " ".join(snakemake_exports + snakemake_cmd + snakemake_log)

    if args.verbose:
        print("\n", cmd, "\n")

    # write log file
    with open(os.path.join(args.outdir, logfile_name), "w") as f:
        f.write(" ".join(sys.argv)+"\n\n")
        f.write(cmd+"\n\n")

    ## Run snakemake
    p = subprocess.Popen(cmd, shell=True)
    if args.verbose:
        print("PID:", p.pid, "\n")
    try:
        p.wait()
    except:
        print("\nWARNING: Snakemake terminated!!!")
        if p.returncode != 0:
            if p.returncode:
                print("Returncode:", p.returncode)

            # kill snakemake and child processes
            subprocess.call(["pkill", "-SIGTERM", "-P", str(p.pid)])
            print("SIGTERM sent to PID:", p.pid)

    ## remove temp dir
    if (temp_path != "" and os.path.exists(temp_path)):
        shutil.rmtree(temp_path, ignore_errors=True)
        if args.verbose:
            print("temp dir removed: "+temp_path+"\n")


if __name__ == "__main__":
    main()
